{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noamiel/AdvancedProgrammingWebApp/blob/main/ImageProcessingProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHlAWQ0p-jil"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from matplotlib import *\n",
        "import sys\n",
        "import pylab as pl\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# sudo pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jO8wwPerrW-7",
        "outputId": "c63b8cab-6ea6-4caf-f2ce-f51b4c322ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting omnipose\n",
            "  Downloading omnipose-0.2.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from omnipose) (0.51.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from omnipose) (0.18.3)\n",
            "Collecting cellpose\n",
            "  Downloading cellpose-2.0.5-py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 24.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from omnipose) (1.21.6)\n",
            "Collecting edt\n",
            "  Downloading edt-2.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 63.9 MB/s \n",
            "\u001b[?25hCollecting ncolor\n",
            "  Downloading ncolor-1.1.2-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from omnipose) (1.4.1)\n",
            "Collecting fastremap\n",
            "  Downloading fastremap-1.13.0-cp37-cp37m-manylinux2010_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 38.3 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting imagecodecs\n",
            "  Downloading imagecodecs-2021.11.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.0 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from cellpose->omnipose) (2021.11.2)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (from cellpose->omnipose) (0.34.0)\n",
            "Collecting numba\n",
            "  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from cellpose->omnipose) (1.11.0+cu113)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from cellpose->omnipose) (5.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cellpose->omnipose) (4.64.0)\n",
            "Collecting llvmlite\n",
            "  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 10 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->omnipose) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->cellpose->omnipose) (4.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->omnipose) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->omnipose) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->omnipose) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->omnipose) (1.3.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->omnipose) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->omnipose) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->omnipose) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->omnipose) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->omnipose) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->omnipose) (1.15.0)\n",
            "Installing collected packages: llvmlite, opencv-python-headless, numba, imagecodecs, fastremap, ncolor, edt, cellpose, omnipose\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed cellpose-2.0.5 edt-2.3.0 fastremap-1.13.0 imagecodecs-2021.11.20 llvmlite-0.38.1 ncolor-1.1.2 numba-0.55.2 omnipose-0.2.1 opencv-python-headless-4.5.5.64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-81df24d45b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install omnipose'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0momnipose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/omnipose/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/omnipose/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0medt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinary_dilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_opening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;31m#again I need to test against skimage labelling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mmodule_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcv_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodule_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpreviously_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mC_BUILTIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_package\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_registerMatType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmat_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_registerMatType' from 'cv2.cv2' (/usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install omnipose\n",
        "import omnipose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv3-QVvplqEo"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNjO4CKY3Y5B"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "%cd /gdrive/My Drive/Colab Notebooks/project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BNDXzRPKgjz"
      },
      "outputs": [],
      "source": [
        "def plotSamplesOneHots(labels_of_samples, output_file=False):\n",
        "    '''\n",
        "    labels_of_samples of shape (num_samples, x, y, num_onehots)\n",
        "    '''\n",
        "    if len(labels_of_samples.shape) != 4:\n",
        "        print(\"Incorrect input size - should be (num_samples, x, y, num_onehots)\")\n",
        "    num_samples = labels_of_samples.shape[0]\n",
        "    num_onehots = labels_of_samples.shape[1]\n",
        "    figure_size = (4*num_onehots, 4*num_samples)\n",
        "    fig, ax = plt.subplots(num_samples, num_onehots, sharex=True, sharey=True, figsize=figure_size)\n",
        "    for i in range(num_samples):\n",
        "        for j in range(num_onehots):\n",
        "            ax[i, j].imshow(labels_of_samples[i,j,...], aspect=\"auto\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "    if output_file == True:\n",
        "        fig.savefig(output_file)\n",
        "        \n",
        "def makeXbyY(data, X, Y):\n",
        "    '''\n",
        "    Crop data to size X by Y\n",
        "    '''\n",
        "    if len(data.shape) < 3:\n",
        "        print('Input should be of size (num_samples, x, y,...)')\n",
        "    data_x_start = int((data.shape[1]-X)/2)\n",
        "    data_y_start = int((data.shape[1]-Y)/2)\n",
        "    arrayXbyY = data[:, (data_x_start):(data_x_start + X), (data_y_start):(data_y_start + Y),...]\n",
        "    return arrayXbyY\n",
        "\n",
        "def findNearestNeighbourLabel(array):\n",
        "    center = int(array.shape[0]/2)\n",
        "    labels_count = np.zeros(5)\n",
        "    for x in range(array.shape[0]):\n",
        "        for y in range(array.shape[1]):\n",
        "            if (x != center) or (y != center):\n",
        "                temp_label = array[x, y]\n",
        "                labels_count[temp_label] += 1\n",
        "    return labels_count.argmax()\n",
        "\n",
        "def cleanLabelNearestNeighbour(label,num_of_classes):\n",
        "    '''\n",
        "    Corrects incorrect labels in a single image based on a threshold on the number of \n",
        "    nearest neighbours with the same label\n",
        "    '''\n",
        "    x_length = label.shape[0]\n",
        "    y_length = label.shape[1]\n",
        "    # num_of_classes = 4\n",
        "    cleaned_labels = np.zeros((x_length, y_length, 4))\n",
        "    for x in range(1,x_length-1):\n",
        "        for y in range(1, y_length-1):\n",
        "            temp_label = label[x,y]\n",
        "            if temp_label >3: # if labeled as 4 or above\n",
        "                temp_label = findNearestNeighbourLabel(label[(x-1):(x+2), (y-1):(y+2)])\n",
        "                cleaned_labels[x, y, temp_label] = 1\n",
        "            elif temp_label > 0:\n",
        "                num_labels_in_3x3 = len(np.where(label[(x-1):(x+2), (y-1):(y+2)]==temp_label)[0])\n",
        "                if num_labels_in_3x3 > 3:\n",
        "                    cleaned_labels[x, y, temp_label] = 1\n",
        "                else:\n",
        "                    temp_label = findNearestNeighbourLabel(label[(x-1):(x+2), (y-1):(y+2)])\n",
        "                    cleaned_labels[x, y, temp_label] = 1\n",
        "        non_zero_array = cleaned_labels[..., 1:].sum(axis=2).astype('bool')\n",
        "        cleaned_labels[..., 0] = np.ones((x_length, y_length), dtype='bool')^non_zero_array\n",
        "    return cleaned_labels\n",
        "\n",
        "def cleanLabelNearestNeighbour_alllabels(labels):    \n",
        "    '''\n",
        "    Cleans incorrect labels\n",
        "    '''\n",
        "    num_labels = labels.shape[0] # count of data set\n",
        "    num_of_classes = 4\n",
        "    cleaned_dim = list(labels.shape) #[13434, 94, 93]\n",
        "    cleaned_dim.append(num_of_classes) # [13434, 94, 93,4]\n",
        "    cleaned_labels = np.zeros(cleaned_dim)\n",
        "    for image_i in range(num_labels):\n",
        "        # print('Preprocessing image %d of %d' % (image_i, num_labels))\n",
        "        cleaned_labels[image_i,...] = cleanLabelNearestNeighbour(labels[image_i, ...],num_of_classes)\n",
        "    return cleaned_labels\n",
        "\n",
        "def meanIOU_per_image(y_pred, y_true):\n",
        "    '''\n",
        "    Calculate the IOU, averaged across images\n",
        "    '''\n",
        "    if len(y_pred.shape) < 3 or (y_pred.shape[2]<4):\n",
        "        print('Wrong dimensions: one hot encoding expected')\n",
        "        return\n",
        "    y_pred = y_pred.astype('bool')\n",
        "    y_true = y_true.astype('bool')\n",
        "    IUs = []\n",
        "    for layer in range(y_true.shape[1]):\n",
        "        intersection = y_pred[:,layer,...] & y_true[:,layer,...]\n",
        "        union = y_pred[:,layer,...] | y_true[:,layer,...]\n",
        "        if union.sum() == 0:\n",
        "            IUs.append(1)\n",
        "        else:\n",
        "            IUs.append(intersection.sum()/union.sum())\n",
        "    return sum(IUs)/len(IUs)\n",
        "\n",
        "def meanIOU(y_pred, y_true):\n",
        "    '''\n",
        "    Calculate the mean IOU, with the mean taken over classes\n",
        "    '''\n",
        "    if len(y_pred.shape) < 4 or (y_pred.shape[1]<4):\n",
        "        print('Wrong dimensions: one hot encoding expected')\n",
        "        return\n",
        "    y_pred = y_pred.astype('bool')\n",
        "    y_true = y_true.astype('bool')\n",
        "    IUs = []\n",
        "    for layer in range(y_true.shape[1]):\n",
        "        intersection = y_pred[:,layer,...] & y_true[:,layer,...]\n",
        "        union = y_pred[:,layer,...] | y_true[:,layer,...]\n",
        "        if union.sum() == 0:\n",
        "            IUs.append(1)\n",
        "        else:\n",
        "            IUs.append(intersection.sum()/union.sum())\n",
        "    return sum(IUs)/len(IUs)\n",
        "\t\n",
        "def IOU(y_pred, y_true):\n",
        "    '''\n",
        "    Calculate the IOU for each class seperately\n",
        "    '''\n",
        "    if len(y_pred.shape) < 4 or (y_pred.shape[1]<4):\n",
        "        print('Wrong dimensions: one hot encoding expected')\n",
        "        return\n",
        "    y_pred = y_pred.astype('bool')\n",
        "    y_true = y_true.astype('bool')\n",
        "    #print(y_pred)\n",
        "    #print(y_true)\n",
        "    IUs = []\n",
        "    for layer in range(y_true.shape[1]):\n",
        "        intersection = y_pred[:,layer,...] & y_true[:,layer,...]\n",
        "        union = y_pred[:,layer,...] | y_true[:,layer,...]\n",
        "        #print(intersection.sum(), union.sum())\n",
        "        if union.sum() == 0:\n",
        "            IUs.append(1)\n",
        "        else:\n",
        "            IUs.append(intersection.sum()/union.sum())\n",
        "    return IUs\n",
        "\n",
        "# One-hot encoding\n",
        "def oneHotEncode(initial_array):\n",
        "    '''\n",
        "    One hot encode the labels\n",
        "    '''\n",
        "    allowed_max_class_num = 3\n",
        "    output_shape = list(initial_array.shape)\n",
        "    output_shape[-1] = initial_array.max()\n",
        "    output_array_dims = list(initial_array.shape)\n",
        "    output_array_dims.append(4)\n",
        "    output_array = np.zeros(output_array_dims)\n",
        "    for image_i in range(0, initial_array.shape[0]):\n",
        "        for class_num in range(0, allowed_max_class_num):\n",
        "            for x in range(0, initial_array.shape[1]):\n",
        "                for y in range(0, initial_array.shape[2]):\n",
        "                    if initial_array[image_i, x, y] == class_num:\n",
        "                        output_array[image_i, x, y, class_num] = 1\n",
        "\n",
        "        class_num = allowed_max_class_num\n",
        "        for x in range(0, initial_array.shape[1]):\n",
        "            for y in range(0, initial_array.shape[2]):\n",
        "                if initial_array[image_i, x, y] >= allowed_max_class_num:\n",
        "                    output_array[image_i, x, y, class_num] = 1\n",
        "    return output_array\n",
        "\n",
        "# Global Accuracy\n",
        "def globalAccuracy(y_pred, y_true):\n",
        "    # Calculate the global accuracy (ie. percent of pixels correctly labelled)\n",
        "    \n",
        "    y_pred = y_pred.astype('bool')\n",
        "    y_true = y_true.astype('bool')\n",
        "\n",
        "    correct = y_pred & y_true\n",
        "    num_correct = correct.sum()\n",
        "    num_total = 1\n",
        "    shape_dim=list(y_true.shape)\n",
        "    shape_dim.remove(4)\n",
        "    shape_dim\n",
        "    for dim in shape_dim:\n",
        "        # print(dim)\n",
        "        num_total = num_total*dim\n",
        "    return num_correct/num_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAgy7QpsLekh"
      },
      "outputs": [],
      "source": [
        "!wget 'https://github.com/jeanpat/DeepFISH/raw/master/dataset/LowRes_13434_overlapping_pairs.h5'\n",
        "!mv 'LowRes_13434_overlapping_pairs.h5' dataset/\n",
        "\n",
        "file_path = 'dataset/LowRes_13434_overlapping_pairs.h5'\n",
        "h5f = h5py.File(file_path,'r')\n",
        "xdata = h5f['dataset_1'][...,0]\n",
        "labels = h5f['dataset_1'][...,1]\n",
        "h5f.close()\n",
        "print(f'Shape of Images: {xdata.shape} \\nShape of Labels: {labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_3SBcS8aZ4q"
      },
      "outputs": [],
      "source": [
        "# First overlapped chromosome image\n",
        "# This is grayscale image with shape (94, 93)\n",
        "xdata[0].shape\n",
        "\n",
        "# It is observed that some intensities of pixels are negative. I am not able to figure out why?\n",
        "np.unique(xdata[0])\n",
        "\n",
        "# Though negative intensities quantity is not much.\n",
        "\n",
        "unique, counts = np.unique(xdata[0], return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)\n",
        "\n",
        "# Image\n",
        "\n",
        "fig = pl.figure(figsize = (5,5)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(xdata[0], aspect=\"auto\")\n",
        "\n",
        "# Label of the first overlapped chromosome image\n",
        "# Lets see the unique intensity values of pixels\n",
        "#np.unique(labels[0])\n",
        "unique, counts = np.unique(labels[0], return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)\n",
        "\n",
        "# This clearly indicates the masks for the four classes\n",
        "# Image:\n",
        "fig = pl.figure(figsize = (5,5)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(labels[0], aspect=\"auto\")\n",
        "\n",
        "# But we can observe that there are different coulors at the boundaries. So cleaning is requried.\n",
        "\n",
        "# Clean the Labels\n",
        "labels_cleaned = cleanLabelNearestNeighbour_alllabels(labels)\n",
        "print(f'Shape of Images: {xdata.shape} \\nShape of Labels: {labels_cleaned.shape}')\n",
        "\n",
        "# Reshape image to height = width = 88\n",
        "xdata_equal = makeXbyY(xdata, 88, 88)\n",
        "labels_equal = makeXbyY(labels_cleaned, 88, 88)\n",
        "\n",
        "print(f'Shape of Images: {xdata_equal.shape} \\nShape of Labels: {labels_equal.shape}')\n",
        "\n",
        "# Reshape Data and Labels\n",
        "# Add one 1 empty channel for gray scale Images (13434, 88, 88) to (13434, 1, 88, 88)\n",
        "# Reshape labels from (13434, 88, 88, 4) to (13434, 4, 88, 88)\n",
        "xdata1 = np.expand_dims(xdata_equal, axis=1)\n",
        "labels1 = np.transpose(labels_equal, (0, 3, 1, 2))\n",
        "print(f'Shape of Images: {xdata1.shape} \\nShape of Labels: {labels1.shape}')\n",
        "\n",
        "# Lets see first two images and its final labels\n",
        "fig = pl.figure(figsize = (5,5)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(xdata1[0][0], aspect=\"auto\")\n",
        "\n",
        "fig = pl.figure(figsize = (5,5)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(xdata1[1][0], aspect=\"auto\")\n",
        "\n",
        "plotSamplesOneHots(labels1[0:2])\n",
        "\n",
        "# Save the procossed data\n",
        "np.save('dataset/xdata_88x88', xdata1)\n",
        "np.save('dataset/ydata_88x88_0123_onehot', labels1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "QMzP0J88bEgZ",
        "outputId": "52d5201b-226e-4dfd-bdb7-ebc6645f97f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of Images: (13434, 1, 88, 88) \n",
            "Shape of Labels: (13434, 4, 88, 88)\n",
            "torch.Size([1, 1, 88, 88])\n",
            "torch.Size([1, 4, 88, 88])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f69a2fc0890>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the processed data\n",
        "xdata_loaded = np.load('dataset/xdata_88x88.npy')\n",
        "labels_loaded = np.load('dataset/ydata_88x88_0123_onehot.npy')\n",
        "\n",
        "print(f'Shape of Images: {xdata_loaded.shape} \\nShape of Labels: {labels_loaded.shape}')\n",
        "\n",
        "# Dataset Conversion in Pytorch format\n",
        "\n",
        "class ChromosomeDataset(Dataset):\n",
        "  def __init__(self, xdata_loaded, labels_loaded, transform=None):\n",
        "    super().__init__()\n",
        "    self.transform = transform\n",
        "        \n",
        "  def __len__(self):\n",
        "    return xdata_loaded.shape[0]\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    return xdata_loaded[idx], labels_loaded[idx]\n",
        "\n",
        "batch_size = 1\n",
        "dataset = ChromosomeDataset(xdata_loaded, labels_loaded)\n",
        "train_ds, test_ds = torch.utils.data.random_split(dataset, (12434, 1000)) # train on 12434 and tested on 1000\n",
        "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "xb, yb = next(iter(train_dataloader))\n",
        "print(xb.shape)\n",
        "print(yb.shape)\n",
        "\n",
        "fig = pl.figure(figsize = (5,5)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(xb.cpu().detach().numpy()[0][0], aspect=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tHO6aehHh79",
        "outputId": "f8b05ea3-7118-41d9-e7ef-4b7686862c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-02 08:17:29--  https://raw.githubusercontent.com/jvanvugt/pytorch-unet/master/unet.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4320 (4.2K) [text/plain]\n",
            "Saving to: ‘unet.py’\n",
            "\n",
            "unet.py             100%[===================>]   4.22K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-06-02 08:17:30 (1.37 MB/s) - ‘unet.py’ saved [4320/4320]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "UNet                                     [1, 4, 88, 88]            --\n",
              "├─ModuleList: 1-1                        --                        --\n",
              "│    └─UNetConvBlock: 2-1                [1, 64, 88, 88]           --\n",
              "│    │    └─Sequential: 3-1              [1, 64, 88, 88]           37,568\n",
              "│    └─UNetConvBlock: 2-2                [1, 128, 44, 44]          --\n",
              "│    │    └─Sequential: 3-2              [1, 128, 44, 44]          221,440\n",
              "│    └─UNetConvBlock: 2-3                [1, 256, 22, 22]          --\n",
              "│    │    └─Sequential: 3-3              [1, 256, 22, 22]          885,248\n",
              "│    └─UNetConvBlock: 2-4                [1, 512, 11, 11]          --\n",
              "│    │    └─Sequential: 3-4              [1, 512, 11, 11]          3,539,968\n",
              "├─ModuleList: 1-2                        --                        --\n",
              "│    └─UNetUpBlock: 2-5                  [1, 256, 22, 22]          --\n",
              "│    │    └─Sequential: 3-5              [1, 256, 22, 22]          131,328\n",
              "│    │    └─UNetConvBlock: 3-6           [1, 256, 22, 22]          1,769,984\n",
              "│    └─UNetUpBlock: 2-6                  [1, 128, 44, 44]          --\n",
              "│    │    └─Sequential: 3-7              [1, 128, 44, 44]          32,896\n",
              "│    │    └─UNetConvBlock: 3-8           [1, 128, 44, 44]          442,624\n",
              "│    └─UNetUpBlock: 2-7                  [1, 64, 88, 88]           --\n",
              "│    │    └─Sequential: 3-9              [1, 64, 88, 88]           8,256\n",
              "│    │    └─UNetConvBlock: 3-10          [1, 64, 88, 88]           110,720\n",
              "├─Conv2d: 1-3                            [1, 4, 88, 88]            260\n",
              "==========================================================================================\n",
              "Total params: 7,180,292\n",
              "Trainable params: 7,180,292\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 4.34\n",
              "==========================================================================================\n",
              "Input size (MB): 0.03\n",
              "Forward/backward pass size (MB): 35.93\n",
              "Params size (MB): 28.72\n",
              "Estimated Total Size (MB): 64.68\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!rm unet.py\n",
        "!wget https://raw.githubusercontent.com/jvanvugt/pytorch-unet/master/unet.py\n",
        "\n",
        "from unet import UNet\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(n_classes=4, depth=4, padding=True, up_mode='upsample').to(device)\n",
        "optim = torch.optim.Adam(model.parameters())\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "summary(model, input_size=(1,1, 88, 88))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53nBbpqbHjCH",
        "outputId": "d1dfcedd-0547-44b1-fd06-b90d4fda64a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- epoch: 0 ----------\n",
            "train loss: 0.13985848814575308\n",
            "Accuracy per epoch: 0.9656481885512531\n",
            "Mean IOU per epoch: [0.99762004 0.12388026 0.63594563 0.52964195]\n",
            "---------- epoch: 1 ----------\n",
            "train loss: 0.06139117653829354\n",
            "Accuracy per epoch: 0.9718736831295687\n",
            "Mean IOU per epoch: [0.99904986 0.29136831 0.66120065 0.66271852]\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "epochs = 2\n",
        "learning_rate = 0.00001\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(f'---------- epoch: {epoch} ----------')\n",
        "  running_loss = []\n",
        "  IOU_per_epoch = []\n",
        "  accuracy_per_epoch = []\n",
        "\n",
        "  for i, (X, y) in enumerate(train_dataloader):\n",
        "    optim.zero_grad()\n",
        "\n",
        "    X = X.float().to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y1 = torch.argmax(y, dim=1)\n",
        "    outputs = model(X)\n",
        "    \n",
        "    #print(outputs.shape, y.shape)\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    loss = loss(outputs, y1)\n",
        "    #loss = Variable(loss, requires_grad = True)\n",
        "\n",
        "    optim.zero_grad()\n",
        "\n",
        "    a = list(model.parameters())[0].clone()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    b = list(model.parameters())[0].clone()\n",
        "    #print(torch.equal(a.data, b.data))\n",
        "    \n",
        "    #running_loss += loss.item()\n",
        "    running_loss.append(loss.item())\n",
        "\n",
        "    outputs1 = torch.argmax(outputs, dim=1)\n",
        "    outputs2 = oneHotEncode(outputs1.cpu().detach().numpy())\n",
        "    \n",
        "    IOU_per_epoch.append(IOU(np.transpose(outputs2, (0,3,1,2)), y.cpu().detach().numpy()))\n",
        "    accuracy_per_epoch.append(globalAccuracy(np.transpose(outputs2, (0,3,1,2)), y.cpu().detach().numpy()))\n",
        "\n",
        "  #print(np.unique(running_loss))\n",
        "  #print(running_loss)\n",
        "  training_loss = sum(running_loss)/len(running_loss)\n",
        "  print(f'train loss: {training_loss}')\n",
        "\n",
        "  accuracy_per_epoch = np.average(np.stack(accuracy_per_epoch, axis=0))\n",
        "  print(f'Accuracy per epoch: {accuracy_per_epoch}')\n",
        "  mean_IOU_per_epoch = np.average(np.stack(IOU_per_epoch, axis=0), axis=0)\n",
        "  print(f'Mean IOU per epoch: {mean_IOU_per_epoch}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiWmSEupJft8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "effe5859-f546-4612-e5d0-f79e917fd7fe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f85f92474079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check point code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/projects/chromosomes/segmentation_unet/model/unet_chromosome_01.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# check point code\n",
        "PATH = '/content/drive/MyDrive/projects/chromosomes/segmentation_unet/model/unet_chromosome_01.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkEPOMXTJpka"
      },
      "outputs": [],
      "source": [
        "y_pred_test=[]\n",
        "true_y_pred_test=[]\n",
        "i = 0\n",
        "model.eval()\n",
        "for i, (X, y) in enumerate(test_dataloader):\n",
        "  \n",
        "  X = X.float().to(device)\n",
        "  y = y.to(device)\n",
        "\n",
        "  #y1 = torch.argmax(y, dim=1)\n",
        "  outputs = model(X)\n",
        "\n",
        "  true_y_pred_test.append(y.cpu().detach().numpy())\n",
        "  y_pred_test.append(outputs.cpu().detach().numpy())\n",
        "\n",
        "y_pred_test1 = np.stack(y_pred_test, axis=1)[0,:,:,:,:]\n",
        "true_y_pred_test1 = np.stack(true_y_pred_test, axis=1)[0,:,:,:,:]\n",
        "\n",
        "testIOU = IOU(y_pred_test1, true_y_pred_test1)\n",
        "print(f'testIOU: {testIOU}')\n",
        "\n",
        "# Global Accuracy \n",
        "global_test_accuracy = globalAccuracy(np.transpose(oneHotEncode(np.argmax(y_pred_test1, axis=1)), (0,3,1,2)), true_y_pred_test1)\n",
        "print(f'Global Test Acuracy: {global_train_accuracy}')\n",
        "del y_pred_test1\n",
        "del true_y_pred_test1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt_LEP8iqj-x"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Load data\n",
        "# xdata = np.load('xdata_88x88.npy')\n",
        "# labels = np.load('ydata_88x88_0123_onehot.npy')\n",
        "# train_test_boundary_index = round(13434*.8)\n",
        "\n",
        "# model = OverlapSegmentationNet(input_shape=(88,88,1))\n",
        "\n",
        "# # Choose loss\n",
        "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# # Specify the number of epochs to run\n",
        "# num_epoch = 5\n",
        "# for i in range(num_epoch):\n",
        "    \n",
        "#     # Fit\n",
        "#     model.fit(x=xdata, y=labels, epochs=1, validation_split=0.2) \n",
        "#     os.makedirs('models', exist_ok=True)\n",
        "#     filename = 'models/savedmodel_' + str(i) + 'epoch'\n",
        "#     model.save(filename)\n",
        "    \n",
        "#     # Predict and plot images\n",
        "#     predictions = model.predict(xdata[0:4,...])\n",
        "#     utilities.plotSamplesOneHots(predictions[0:4,...].round())\n",
        "   \n",
        "#     # Calculate mIOU\n",
        "#     y_pred_train = model.predict(xdata[0:train_test_boundary_index,...]).round()\n",
        "#     trainIOU = utilities.IOU(y_pred_train, labels[0:train_test_boundary_index,...])\n",
        "#     print('Training IOU: ' + str(trainIOU))\n",
        "#     trainAccuracy = utilities.globalAccuracy(y_pred_train, labels[0:train_test_boundary_index,...])\n",
        "#     print('Training accuracy: ' + str(trainAccuracy))\n",
        "#     del y_pred_train\n",
        "    \n",
        "#     y_pred_test = model.predict(xdata[train_test_boundary_index:,...]).round()\n",
        "#     testIOU = utilities.IOU(y_pred_test, labels[train_test_boundary_index:,...])\n",
        "#     print('Testing IOU: ' + str(testIOU))\n",
        "#     testAccuracy = utilities.globalAccuracy(y_pred_test, labels[train_test_boundary_index:,...])\n",
        "#     print('Testing accuracy: ' + str(testAccuracy))\n",
        "#     del y_pred_test\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOfC0WTEmpzhVvHZofOecM3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}